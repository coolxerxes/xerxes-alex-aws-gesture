{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to split into train and test, make standardization, and build the model, then pickle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url=\"C:\\\\Users\\\\Jo0od\\\\CaptoNew\\\\dataset_all.csv\"\n",
    "dataset=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and standardization\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split train and test\n",
    "train_set, test_set = train_test_split(dataset, test_size=0.1, random_state=42,stratify=dataset['Label'])\n",
    "train_set.reset_index(drop=True, inplace=True)\n",
    "test_set.reset_index(drop=True, inplace=True)\n",
    "#divide X and y\n",
    "train_X = train_set.drop(\"Label\", axis=1)\n",
    "train_y = train_set[\"Label\"].copy()\n",
    "test_X = test_set.drop(\"Label\", axis=1)\n",
    "test_y = test_set[\"Label\"].copy()\n",
    "#data standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "scaled=scaler.transform(train_X)  #scaled is numby array\n",
    "train_X = pd.DataFrame(scaled, columns=train_X.columns)\n",
    "scaled=scaler.transform(test_X)\n",
    "test_X = pd.DataFrame(scaled, columns=test_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.38226344e-01,  1.42382772e-01,  1.33138776e-01,  1.43612830e-01,\n",
       "        1.35090335e-01,  1.28177173e-01,  1.24070771e-01,  1.26406575e-01,\n",
       "        8.86863944e-02,  1.01046562e-01,  7.73193691e-02,  6.75527362e-02,\n",
       "        8.92729647e-02,  1.00234470e-01,  9.68895111e-02,  1.03750130e-01,\n",
       "       -1.95675331e-02, -2.50561269e-02, -1.66425584e-02, -5.74941955e-02,\n",
       "       -3.84331109e-02, -6.49572393e-02, -6.05694787e-02, -6.02554309e-02,\n",
       "        8.61107129e-02,  8.67801929e-02,  1.24631839e-01,  6.35090650e-02,\n",
       "        8.39867509e-02,  9.23590328e-02,  5.78388930e-02,  7.95844120e-02,\n",
       "        1.25210791e-02,  4.05570617e-03,  4.36095679e-02,  1.93215911e-02,\n",
       "        2.45577216e-02,  3.18038905e-02,  1.81062484e-03,  2.02135387e-02,\n",
       "       -1.99722771e-02, -1.94858764e-02, -1.92452124e-02,  4.35951830e-03,\n",
       "       -7.25246948e-03, -1.56581254e-02, -1.45042421e-02, -1.80924125e-02,\n",
       "        3.66678202e+03,  2.87491615e+03,  3.48464210e+03,  3.08385937e+03,\n",
       "        2.97640066e+03,  3.71974873e+03,  2.54937380e+03,  3.51782255e+03,\n",
       "        3.42957764e+03,  2.89437681e+03,  3.27367620e+03,  2.86640327e+03,\n",
       "        3.25290066e+03,  2.38631276e+03,  4.95261233e+03,  3.24553214e+03,\n",
       "        3.36740170e+03,  2.09390322e+03,  2.87508705e+03,  2.38056417e+03,\n",
       "        2.57704253e+03,  2.82606868e+03,  2.86660906e+03,  2.94134557e+03,\n",
       "        3.20039709e+03,  1.76802649e+03,  2.30524957e+03,  1.74626678e+03,\n",
       "        1.85377239e+03,  2.09707400e+03,  2.43706435e+03,  2.40958767e+03,\n",
       "        1.84278665e+03,  1.50300070e+03,  1.38933620e+03,  1.26085919e+03,\n",
       "        1.00570161e+03,  1.25866029e+03,  1.81178424e+03,  1.67013112e+03])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.79527381e-02, 9.85943907e-02, 9.38305651e-02, 8.30806753e-02,\n",
       "       8.08372621e-02, 8.17090406e-02, 8.49157951e-02, 8.32185394e-02,\n",
       "       1.34775549e-02, 3.54549414e-02, 1.93747709e-02, 6.19312064e-03,\n",
       "       9.82030045e-03, 1.26152120e-02, 2.17513420e-02, 1.66656776e-02,\n",
       "       7.78825513e-02, 1.19829750e-01, 8.70932717e-02, 4.19275465e-02,\n",
       "       3.45421471e-02, 3.22339687e-02, 3.66499223e-02, 3.34865286e-02,\n",
       "       1.67635355e-02, 8.50871704e-02, 4.26105565e-02, 2.39560325e-02,\n",
       "       1.39563213e-02, 2.81558977e-02, 8.05239494e-02, 1.38768623e-02,\n",
       "       4.06950763e-02, 8.06550644e-02, 3.91533533e-02, 2.35350976e-02,\n",
       "       2.03007374e-02, 4.21168096e-02, 9.03379006e-02, 3.18566995e-02,\n",
       "       9.88623788e-03, 2.02774476e-02, 1.15612155e-02, 2.11832992e-03,\n",
       "       5.33382143e-03, 7.42111506e-03, 1.01336335e-02, 9.76580951e-03,\n",
       "       5.97005337e+05, 1.67080738e+07, 3.77207961e+06, 1.62271033e+06,\n",
       "       3.11145589e+06, 3.17379016e+07, 1.44033482e+08, 3.12216175e+05,\n",
       "       3.23068868e+04, 8.45417861e+06, 2.82103039e+06, 2.10631213e+06,\n",
       "       8.94649557e+06, 1.03692294e+08, 4.80534362e+08, 3.74178735e+05,\n",
       "       4.28965910e+05, 2.50991361e+07, 5.47725719e+06, 2.95157037e+06,\n",
       "       2.01142315e+06, 1.56205046e+06, 1.87578738e+06, 1.37306718e+06,\n",
       "       7.76304302e+05, 3.47967876e+06, 1.76516566e+06, 2.03471402e+06,\n",
       "       1.42672133e+06, 1.77755521e+06, 2.30795588e+06, 1.63877038e+06,\n",
       "       1.11816381e+06, 5.41876467e+06, 1.79298419e+06, 1.63256174e+06,\n",
       "       1.27242846e+06, 2.70161754e+06, 8.13696764e+06, 1.13344415e+06])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96969697, 0.96969697, 0.90625   , 0.90625   , 0.875     ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "forest_clf = RandomForestClassifier( random_state=42)\n",
    "forest_clf.fit(train_X, train_y)\n",
    "scores=cross_val_score(forest_clf, train_X, train_y, cv=5, scoring=\"accuracy\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.96969697 0.96969697 0.90625    0.90625    0.875     ]\n",
      "Mean: 0.9253787878787879\n",
      "Standard deviation: 0.037942181800466025\n"
     ]
    }
   ],
   "source": [
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 17,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  2, 16,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 18,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 16,  2,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  3, 14,  0,  0,  0],\n",
       "       [ 1,  0,  0,  1,  0,  0, 16,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 18,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1, 17]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#error analysis\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "train_y_pred = cross_val_predict(forest_clf, train_X, train_y, cv=5)\n",
    "conf_mx = confusion_matrix(train_y,train_y_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.94444444, 0.88888889, 1.        , 0.88888889,\n",
       "       0.77777778, 0.88888889, 1.        , 0.94444444])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "recall_score(train_y,train_y_pred,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94736842, 0.89473684, 0.94117647, 0.9       , 0.84210526,\n",
       "       0.875     , 1.        , 0.94736842, 1.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(train_y,train_y_pred,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9259259259259259"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_y,train_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. from the confusion matrix, it is clear it classify sign 1 as sign 6. The total of each sign in tyrain set is 18.\n",
    "2. from recall, sometimes it cannot capture sign 1 and 4. Recall is the actual percentage of each sign that the model can capture correctly.\n",
    "3. from precision, when the model say sign 6, the chance of true classification is 0.85. Precision is the percentage of correct classifications among all classifications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions = forest_clf.predict(test_X)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, final_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump, load\n",
    "# save the model to disk\n",
    "modelName = 'C:\\\\Users\\\\Jo0od\\\\CaptoNew\\\\finalized_model.pkl'\n",
    "dump(forest_clf, open(modelName, 'wb'))\n",
    "# save the scaler \n",
    "scalerName = 'C:\\\\Users\\\\Jo0od\\\\CaptoNew\\\\scaler.pkl'\n",
    "dump(scaler, open(scalerName, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore the performance of the pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888888888888889"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#file path XXX.sav\n",
    "filename = 'C:\\\\Users\\\\Jo0od\\\\CaptoNew\\\\finalized_model.pkl'\n",
    "loaded_model = load(open(filename, 'rb'))\n",
    "scalerName = 'C:\\\\Users\\\\Jo0od\\\\CaptoNew\\\\scaler.pkl'\n",
    "scaler2 = load(open(scalerName, 'rb'))\n",
    "\n",
    "# 88 used to be 72, changed because of an error\n",
    "scaled_new=scaler2.transform(dataset.iloc[:,0:88])  #scaled is numby array\n",
    "scaled_new = pd.DataFrame(scaled_new)\n",
    "\n",
    "results = loaded_model.predict(scaled_new )\n",
    "accuracy_score(dataset.iloc[:,-1], results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 8, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted sign is:  [6]\n",
      "The predicted sign is:  6 \n",
      "The actual sign is:  6\n"
     ]
    }
   ],
   "source": [
    "#test using the pickled model\n",
    "# load the model from disk\n",
    "\n",
    "#file path XXX.sav\n",
    "filename = 'C:\\\\Users\\\\Jo0od\\\\CaptoNew\\\\finalized_model.pkl'\n",
    "loaded_model = load(open(filename, 'rb'))\n",
    "s=120\n",
    "\n",
    "# 88 used to be 72, changed because of an error\n",
    "dd = np.zeros(shape=(1,88))\n",
    "dd[0][:]=dataset.iloc[s,0:88]\n",
    "some_sign=scaler2.transform(dd)  #scaled is numby array\n",
    "#some_sign = pd.DataFrame(some_sign)\n",
    "result = loaded_model.predict(some_sign)\n",
    "print(\"The predicted sign is: \",result)\n",
    "print(\"The predicted sign is: \",result[0],\"\\nThe actual sign is: \",dataset.iloc[s,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
